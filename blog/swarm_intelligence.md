title: 集群智能
author: Jin Jay
Date: 2016-01
description: 集群智能，蚁群优化算法、粒子群优化算法、蜂群算法等。
keywords: 集群智能
          PSO
          蚁群优化算法
          ACO
          粒子群优化算法
          蜂群算法


# <center>集群智能</center>

&emsp;&emsp;集群智能是分布式、自组织的系统表现出的一种群体智能。集群智能在1989年由Gerardo Beni和Jing Wang在细胞自动机系统中首次提出。

&emsp;&emsp;集群智能系统一般由简单的智能体构成，智能体按照简单的规则进行局部交互，智能体也可以与环境进行交互。集群智能灵感一般来源于自然，尤其是生物系统。比如蚁群、鸟群、动物放牧、细菌生长、鱼群和微生物等。集群智能系统中的智能体遵循简单的规则，没有中心控制结构来指示如何表现。尽管没有集中控制机制来指示这些智能体如何协作，但这些简单的局部交互行为通常能涌现出复杂的全局行为，体现出集群智能。一般认为集群智能系统有如下几个特点：

1. 分布式：无中心控制
2. 随机性：非确定性
3. 自适应：个体根据环境进行策略调整
4. 正反馈：个体好的尝试会对个体产生正反馈
5. 自发涌现：会在群体层面涌现出一种智能

&emsp;&emsp;了解了集群智能系统的特点，接下来介绍几个集群智能系统算法及其相应的改进：

## 蚁群优化算法
&emsp;&emsp;蚁群优化算法(Ant Colony Optimizztion, ACO)首次出现在1992年Marco Dorigo的博士论文中，主要解决的是图中最优路径的搜索，算法思想基于蚁群寻食的过程。作为一种解空间搜索方法，蚁群优化算法出现了多种变体，并扩展到多个领域，解决多种问题。

### 基本的蚁群优化算法
&emsp;&emsp;基本的蚁群优化算法主要体现在如下五点：

- 每个蚂蚁对应一个计算智能体
- 蚂蚁依概率选择候选位置进行移动
- 在经过的路径上留下“信息素”(Pheromone)
- “信息素”随时间挥发
- “信息素”浓度大的路径在后续的选择中会以更高的概率被选取

&emsp;&emsp;下面以旅行商问题为例，来说明蚁群优化算法的实现。

> 问题建模

- $n$个城市的有向图$G=(V,E)$
    $V = \\{1,2,\cdots,n\\} \quad \quad E=\\{(i,j)|i,j\in V\\}$
- 城市之间的距离
    $d\_{ij} \quad$节点$i$和$j$之间的距离
- 目标函数
    $f(w)=\sum\_{l=1}^nd\_{i\_{l+1}j\_{l+1}}$

> 问题求解

&emsp;&emsp;将$m$个蚂蚁随机放置在$n$个城市中，位于城市$i$的第$k$只蚂蚁选择下一个城市$j$的概率为：
$$P\_{ij}^k(t) = \begin{cases} \frac{(\tau\_{ij}(t))^\alpha (\eta\_{ij}(t))^\beta}{\sum\_{k\in allowed}(\tau\_{ik}(t))^\alpha (\eta\_{ik}(t))^\beta}, & j \in allowed \\\\ 0, & otherwise \end{cases}$$
&emsp;&emsp;其中，

- $\tau\_{ij}(t)$表示边$(i,j)$上的信息素浓度；
- $\eta\_{ij}(t) = 1/d\_{ij}$是根据距离定义的启发信息；
- $\alpha , \beta$反映了信息素与启发信息的相对重要性；

&emsp;&emsp;在所有的蚂蚁完成周游后，按照以下公式进行信息素更新：
$$
\begin{align\*}
 & \Delta \tau\_{ij}=f(x)=\begin{cases} \frac{Q}{L\_k}, & ij\in w\_k \\\\ 0, & otherwise \end{cases} \\\\ 
 & \tau\_{ij}(t+1) = \rho\cdot\tau\_{ij}(t+1)+\Delta\tau\_{ij} \\\\
 & \Delta = \sum\_{k=1}^m\Delta\tau\_{ij}^k
\end{align\*}
$$

&emsp;&emsp;其中，$Q$为常数；$w\_k$表示第$k$只蚂蚁在本轮迭代中走过的路径；$L\_k$为路径长度；$\rho$为小于1的常数，反映信息素挥发的速度。

> 伪代码

(1)**初始化** 随机放置蚂蚁
(2)**迭代过程**
```Ruby
k = 1
while k <= IterCount do     # 迭代
    for i = 1 to m do       # 对m只蚂蚁循环
        for j = 1 to n-1 do # 对n个城市循环
            计算蚂蚁选择下一个城市的概率
        end for 
        选定下一个城市l ，将l 置入禁忌表，蚂蚁转移到l
    end for
    计算每只蚂蚁的路径长度
    更新所有蚂蚁路径上的信息素
    k = k + 1
end while
```
(3)**输出结果，结束算法**

> 参数设定

**蚁群大小**:一般情况下，蚁群中的蚂蚁个数不超过TSP图中节点的个数。
**终止条件**:设定迭代轮数；设定最优解连续保持不变的迭代轮数。

### 蚁群优化算法的改进

> ①蚁群系统

&emsp;&emsp;蚁群系统(Ant Colony System, ACS)，主要对基本蚁群算法中的路径选择和信息更新进行了改进：

1. 采用伪随机比率选择规则的路径选择方式，即对于在城市$i$的蚂蚁，按如下式子选择下一个城市j:$$j=\begin{cases} arg \max\_{u\in allowed} \left\\{ \tau(i,u)\cdot \eta^\beta(i,u) \right\\}, &   q \le q\_0 \\\\ , & otherwise \end{cases} $$其中，$q\_0 \in (0,1)$为常数；$q\in (0,1)$为随机数；$\tau(i,u)$表示城市$i$与城市$u$之间的信息素浓度；$\eta(i,u)$表示城市$i$与城市$j$之间的启发式因子，$\beta$表示启发式因子的相对强弱。在选择下一个城市之前随机生成$q$,如果$q$的值小于等于常数$q\_0$，则从城市$i$到所有可行的城市中找出$\\{\tau(i,u)\cdot \eta^\beta(i,u) \\}$最大的城市，即为下一个要选择的城市；如果随机数$q$大于$q\_0$,则按下式来选择下一个城市：$$p\_k(i,j)=\begin{cases} \frac{\tau(i,j)\cdot \left[\eta(i,j)\right]^\beta}{\sum\_{s\in allowed}\tau(i,j)\cdot \left[\eta(i,j)\right]^\beta}, & j \in allowed \\\\ 0, & otherwise \end{cases} $$
2. 局部信息更新，蚂蚁从城市$i$转移到城市$j$后，路径$ij$上的信息素按下式更新：$$\tau\_{ij} = (1-\xi)3\tau\_{ij} + \xi\cdot \tau\_0, \xi\in (0,1) $$其中$\tau\_0$为常数，$\xi$为可调参数。
3. 全局信息更新，针对全局最优解所属的边按下式进行信息更新：$$\begin{align\*} & \tau\_{ij}^{(t+1)}=(1-\rho)3\tau\_{ij}(t)+\rho\cdot\Delta\tau\_{ij}^{gb}(t), \rho\in (0,1) \\\\ & \Delta\tau\_{ij} = \frac1{L^{gb}}\end{align\*} $$其中，$L^{gb}$为当前全局最优解的长度，$\rho$为外激素的蒸发系数。

> ②最大-最小蚂蚁系统

&emsp;&emsp;最大-最小蚂蚁系统(MAX-MIN Ant System, MMAS)主要的改进体现在以下三个方面：

1. 每次循环结束后，只有最优解所属路径上的信息素被更新；
2. 为了避免搜索是出现时滞现象，个路径上的信息素被限制在范围$[\tau\_{min}, \tau\_{max}]$内；
3. 初始时刻，各路径上的信息量取最大值。所有蚂蚁完成一次循环后，按下式对路径上的信息作全局更新：$$\begin{align\*} & \tau\_{ij}^{(t+1)} = (1-\xi)3\tau\_{ij}(t) + \Delta\tau\_{ij}^{best}(t) ,  \rho\in(0,1) \\\\ & \Delta\tau\_{ij}^{best} = \frac1{L^{best}} \end{align\*} $$

> ③基于排序的蚂蚁系统

&emsp;&emsp;基于排序的蚂蚁系统(Rank-based ant system, ASrank)，顾名思义，该系统对某一指标进行了排序：在完成一次循环后，将蚂蚁所经过的路径按从小到大的顺序排列，即$L^1(t) \le L^2(t)\le \cdots L^m(t)$，然后根据路径长度赋予不同的权重，路径较短的权重较大。全局最优解的权重为$w$，第$r$个最优解的权重为$\max\\{0, w-r \\}$，按下式更新各路径上的信息$$\tau\_{ij}^{(t+1)}=(1-\rho)3\tau\_{ij}(t)+ \sum\_{r=1}^{W-1}(w-r)\cdot \Delta\tau\_{ij}^r(t) + w\cdot\Delta\tau\_{ij}^{gb}(t)  $$其中，$\Delta\tau\_{ij}^r(t) = 1/L^r(t), \Delta\tau\_{ij}^{bg}(t) =1/L^{gb} $

&emsp;&emsp;同基本的AS算法相比，这些改进算法的共同之处在于对最优解的加强利用。在ACS和MMAS算法中，只有最优解（全局最优或本次循环最优）所属路经上的信息允许更新。在ASrank中，根据每次循环路经的长短赋予不同的权重，即对较短的路径赋予较大的权重。这样最优解包含的路径将会有更多的机会在下一次被选中。但是，加强对最优解的利用将会导致搜索中的停滞现象。在ACS算法中通过增加局部信息更新来减少路径上的信息量，从而使后面的蚂蚁选择该路径的可能性减少；在MMAS算法中，通过限制信息量的范围，使路径上的信息量不会小于某一最小值，从而避免了所有蚂蚁选择同一条路经的可能性，即避免了搜索中的停滞现象。

&emsp;&emsp;总的来说，蚁群优化算法是一种局部随机搜索算法；适用于在图中寻找优化路径的问题。

## 粒子群优化算法
&emsp;&emsp;粒子群优化算法(PSO)是一种基于种群寻优的启发式搜索算法。在1995年由Kennedy 和Eberhart 首先提出。它的主要启发来源于对鸟群群体运动行为的研究。我们经常可以观察到鸟群表现出来的同步性，虽然每只鸟的运动行为都是互相独立的，但是在整个鸟群的飞行过程中却表现出了高度一致性的复杂行为，并且可以自适应的调整飞行的状态和轨迹。很自然地猜想，鸟群具有这样的复杂飞行行为的原因，可能是因为每只鸟在飞行过程中都遵循了一定的行为规则，并能够掌握邻域内其它鸟的飞行信息。粒子群优化算法借鉴了这样的思想，每个粒子代表待求解问题搜索解空间中的一个潜在解，它相当于一只鸟，“飞行信息”包括粒子当前的位置和速度两个状态量。每个粒子都可以获得其邻域内其它个体的信息，对所经过的位置进行评价，并根据这些信息和位置速度更新规则，改变自身的两个状态量，在“飞行”过程中传递信息和互相学习，去更好地适应环境。随着这一过程的不断进行，粒子群最终能够找到问题的近似最优解。

### 基本的粒子群优化算法

&emsp;&emsp;一般来说，粒子群优化算法有以下几个构成要素：

1. 粒子群
    + 每个粒子对应所求解问题的一个可行解
    + 粒子通过其位置和速度表示
        - 粒子i在第n轮的位置:$x\_n^{(i)}$
        - 粒子i在第n轮的速度:$v\_n^{(i)}$
2. 记录
    + $p\_{best}^{(i)}$:粒子的历史最好位置
    + $g\_{best}$:全局历史最好位置
3. 计算适应度函数
    + 适应度:$f(x)$

> 算法描述

(1)初始化

+ 初始化粒子群：每个粒子的位置和速度，即$x\_0^{(i)}$和$v\_0^{(i)}$
+ $p\_{best}^{(i)}$和$g\_{best}$

(2)循环执行如下散步直至满足结束条件

+ 计算每个粒子的适应度$f(x\_n^{(i)})$
+ 更新每个粒子历史最好适应度及其相应的位置，更新当前全局最好适应度及其相应的位置
+ 更新每个粒子的速度和位置
$$
\begin{align\*}
v\_{n+1}^{(i)} & = v\_n^{(i)} + c\_1\cdot r\_1 \cdot (p\_{best}^{(i)}-x\_n^{(i)}) + c\_2\cdot r\_2 \cdot (g\_{best} - x\_n^{(i)}) \\\\
x\_{n+1}^{(i)} & = x\_n^{(i)} + v\_n^{(i)}
\end{align\*}
$$

&emsp;&emsp;其中，$v\_n{(i)}$代表惯性项，表示保持原有速度不变的倾向；$(p\_{best}^{(i)}-x\_n^{(i)})$代表记忆项，表示回到你是最好位置的倾向；$(g\_{best} - x\_n^{(i)})$代表社会项，表示走向粒子全局最好位置的倾向。

&emsp;&emsp;$c\_1, c\_2$是权重参数，一般取值为2；$r\_1, r\_2$为随机参数，0和1之间的随机数。

> 参数设定

**终止条件**:

- 迭代的轮数
- 最佳位置连续未更新数
- 适应度函数的值达到预期要求

**速度更新参数**：

+ $c\_1 > 0, c\_2 = 0$:每个粒子执行局部搜索；
+ $c\_1 = 0, c\_2 > 0$:粒子群转化为一个随机爬山法；
+ $c\_1  = c\_2 > 0$:粒子逐渐移向$\overrightarrow { { P }\_{ g } }$和$\overrightarrow { { P }\_{ i } }$的加权平均值；
+ $c\_2 > c\_1$:算法比较适合于单峰优化问题；
+ $c\_1 > c\_2$:算法比较适合于多峰优化问题。

### 粒子群优化算法的改进策略
&emsp;&emsp;粒子群算法中粒子向自身最佳位置和邻域或群体历史最佳位置聚集，形成粒子种群的快速趋同效应，容易出现陷入局部极值、早熟收敛或停滞现象。PSO中全局最优或局部最优将信息传给其他粒子，是单向的信息流动，多数情况下，所有的粒子可能更快地收敛于最优解。不过如果加速系数、最大速度等参数太大，粒子群可能错过最优解，算法不会收敛；即使在收敛的情况下，由于所有的粒子都向最优解方向飞去，粒子趋向于同一化，失去了多样性，使得后期收敛速度明显变慢。故而出现了以下几种改进策略：

> ①引入惯性权重

&emsp;&emsp;速度冲量会导致粒子按照先前速度方向继续移动。Yuhui Shi提出了一个惯性权重$w$来控制先前粒子速度的影响：$$v\_{n+1}^{(i)} = w\cdot v\_n^{(i)} + c\_1\cdot r\_1 \cdot (p\_{best}^{(i)}-x\_n^{(i)}) + c\_2\cdot r\_2 \cdot (g\_{best} - x\_n^{(i)})  $$较大的$w$可以加强PSO的全局搜索能力，较小的$w$能加强局部搜索能力。目前采用较多的惯性权值是线性递减权值：$$w\_{LDW} = (w\_{max} - w\_{min})\times \frac{Iteration\_{max} - Iteration\_l}{Iteration\_{max}} + w\_{min} $$其中，$w\_{max} = 0.9, w\_{min}=0.4, Iteration\_{max}$是允许的最大的迭代次数，$Iteration\_l$为当前迭代的次数。

> ②引入收缩因子

&emsp;&emsp;Clerc建议使用收缩因子来保证PSO收敛。速度更新按下式进行：$$v\_{n+1}^{(i)} = \chi (w\cdot v\_n^{(i)} + c\_1\cdot r\_1 \cdot (p\_{best}^{(i)}-x\_n^{(i)}) + c\_2\cdot r\_2 \cdot (g\_{best} - x\_n^{(i)}))$$其中，$\chi$成为收缩因子。使用下式确定$\chi$的值：$$ \chi = \frac2{\left|2-\varphi-\sqrt{\varphi^2-4\varphi} \right|}\\\\ \varphi=c\_1+c\_2 > 4.0 $$收缩因子可以使粒子轨迹最终收敛，且可以有效搜索不同的区域，能得到高质量的解，若与此同时将每维的最大速度设置为一维搜索空间的大小,则可得到更好效果.

&emsp;&emsp;总的来说，粒子群优化算法是一种随机优化算法；适用于求解连续解空间的优化问题。

## 人工蜂群算法
&emsp;&emsp;人工蜂群算法(ABC)由土耳其学者Karaboga于2005年为优化代数问题提出的一种新颖的基于群智能的全局优化算法，主要启发于蜂群的采蜜行为：蜜蜂根据各自的分工进行不同的活动，并实现蜂群信息的共享和交流，从而找到问题的最优解。

### 基本的人工蜂群算法
&emsp;&emsp;人工蜂群算法中，人工蜂群包含三组蜜蜂：

- **雇佣蜂(employed bees)**:与食物源一一对应，带有食物源位置和花蜜量信息；
- **观察蜂(onlookers)**:观察雇佣蜂的舞蹈，选择食物源；
- **侦察蜂(scouts)**:由丢弃了食物源的雇佣蜂转变而来，随机选择一个新的食物源。

&emsp;&emsp;每一个人工雇佣蜂对应一个特定的食物源，也即雇佣蜂的数量与蜂巢附近食物源的数目相同。雇佣蜂根据记忆去到各自的食物源进行局部搜索，当发现更好的食物源后就更新所附的食物源；接着一部分雇佣蜂会返回蜂巢并跳“摇摆舞”，观察蜂通过观察“摇摆舞”来决定选择食物源，追随雇佣蜂到达食物源并在该食物源处进行局部搜索；一部分雇佣蜂会因为食物耗尽等因素放弃食物源成为侦察蜂，侦察蜂随机寻找新的食物源，找到好的食物源后会再次变为雇佣蜂。

&emsp;&emsp;人工蜂群算法是一个迭代寻优算法。初始时随机分布式地生成$K$个食物源，一个食物源的位置表示优化问题的一个可能解，食物源对应的花蜜量对应相应的解的可行性。雇佣蜂的数量与解的数量相同。雇佣蜂在各自记忆的食物源位置进行局部搜索，如果找到好的食物源，就更新食物源信息；否则保留原有的食物源信息。雇佣蜂与观察蜂共享食物源信息后，观察蜂按照一个与食物源花蜜量成正比的概率选择一个食物源。选择一个食物源$i$的概率$p\_i$可表示为：$$p\_i = \frac{f\_i}{\sum\_{j = 1}^K f\_j} \quad (1)$$&emsp;&emsp;其中，$f\_i$表示食物源i所代表的花蜜量(适应度)；K表示食物源总数。按照这样的概率选择食物源，花蜜多的食物源会吸引更多的观察蜂。所有的观察蜂选择完食物源后，每一个观察蜂在该食物源邻域内寻找新的食物源并计算花蜜量。一个食物源$i$和它附带的所有观察蜂所确定的食物源中，花蜜量最多的将是食物源$i$的新位置，这个信息会一并更新到该食物源的雇佣蜂。如果一个食物源在经过预先设定的迭代次数后仍没有改进，那么该食物源会被雇佣蜂抛弃。该雇佣蜂就变为一只侦察蜂，然后随机的选择一个新的食物源位置。侦察蜂获得新的食物源位置后再次变为雇佣蜂。在所有的食物源的新位置确定后，开始下一次迭代过程。人工蜂群算法步骤如下：

1. 初始化：为雇佣蜂初始化食物源位置
2. 迭代进行以下步骤
    - 每一个雇佣蜂通过记忆去到相应的食物源，在食物源位置进行局部搜索，计算花蜜量，如果花蜜量多于原有的，就更新食物源信息，否则保持不变。
    - 每一个观察蜂获取雇佣蜂的共享信息，根据这些食物源信息选择一个食物源，跟随该雇佣蜂去到食物源处进行局部搜索，找到好的食物源时通知相应的雇佣蜂更新食物源信息。
    - 丢弃了食物源的雇佣蜂成为侦察蜂，随机寻找新的食物源代替。
    - 记录到目前为止找到的最好的食物源
3. 算法结束

> 实例解析

&emsp;&emsp;设求解问题的维数为$D$，有$K$个食物源。在第$t$次迭代时食物源$i$的位置表示为：
$$X\_i^{(t)} = [x\_{i1}^{(t)}, x\_{i2}^{(t)},\cdots, x\_{iD}^{(t)}]$$&emsp;&emsp;其中$x\_{id} \in (L\_d, U\_d) \quad d=1,2,\cdots,D$；$L\_d, U\_d$分别表示搜索空间第d个分量的下限和上限。食物源$i$的初始位置可以按下式产生：$$x\_{1d} = L\_d + rand(0,1)(U\_d-L\_d)$$&emsp;&emsp;搜索开始后，雇佣蜂按下式在食物源邻域产生一个新的食物源：$$x\_{id}^\prime = x\_{id} + \varphi(x\_{id}-x\_{jd}) \quad (2)$$&emsp;&emsp;式中，$j\in\\{1,2,\cdots,K \\}, j\neq i$，表示在K个食物源中随机选择一个不等于i的食物源；$\varphi$是一个均匀分布的随机数，作为扰动幅度。当新食物源$X\_i^{(t)^\prime}$的花蜜量大于$X\_i^{(t)}$时，用$X\_i^{(t)^\prime}$代替$X\_i^{(t)}$，否则不变。接着，观察蜂按照概率式(1)选择雇佣蜂，然后观察蜂按照式(2)选择新的食物源，计算花蜜量得到$X\_i^{(t)^\prime}$且采用相同的方式更新$X\_i^{(t)}$。如果食物源$X\_i$经过了$T\_i$次迭代搜索达到了阈值$Limit$没有找到更好的食物源，该食物源的$X\_i$将会被放弃，对应的观察蜂变为侦察蜂。侦察蜂随机产生一个新的食物源代替$X\_i$作为$X\_i$，故有：$$X\_i^{(t+1)} = \begin{cases} L\_d + rand(0,1)(U\_d-L\_d), & T\_i \ge Limit \\\\ X\_i^{(t)}, & T\_i < Limit \end{cases} $$&emsp;&emsp;其中，$T\_i$表示第$i$个食物源位置未更新次数；$Limit$表示设定的食物源未更新次数上限。

> 参数设定

**终止条件**:设定迭代轮数；设定最优解连续保持不变的迭代轮数。

### 人工蜂群算法的改进

&emsp;&emsp;与前两个算法类似，基本的人工蜂群算法也存在早熟收敛、局部搜索能力较弱等问题。对人工蜂群算法进行的改进如下：

> 算法参数调整

&emsp;&emsp;2011年，Karaboga和Akay考虑到有时不可行的解(不合适的食物源)也会被观察蜂追随而更新了观察蜂选择某一个食物源的概率算法，如下式所示：$$p\_i = \begin{cases}0.5+\left(\frac{f\_i}{\sum\_{j=1}^Kf\_j} \times 0.5 \right), & 解可行 \\\\ \left(1-\frac{v\_i}{\sum\_{j=1}^Kv\_j}\times 0.5 \right), & 解不可行 \end{cases} $$其中，$f\_i$是食物源$i$的适应度；$v\_i$是解不可行时的惩罚值。这样使得不可行的解的概率范围约束在$(0,0.5)$范围内，而可行解的概率范围在$(0.5,1)$之间。

> 引入新的参数

&emsp;&emsp;2012年，Li等人提出了改进的ABC算法，称为I-ABC(Improved-ABC)。引入了惯性权重和加速因子来改进搜索过程。在I-ABC中，食物源$i$的邻域解为:$$x\_{id}^\prime = w\_{id}\cdot x\_{id} + 2(\phi\_{id}-0.5)(x\_{id}-x\_{jd}\Phi\_1) + \psi\_{id}(y\_d-x\_{jd})\Phi\_2 $$其中，$w\_{id}$为惯性权重；$y\_d$为第$d$个食物源的目前最好的解；$\phi\_{id}, \psi\_{id}$是$[0,1]$之间的随机数；$\Phi\_1, \Phi\_2$是控制步长的正向参数，也即加速因子。$w\_{id}, \Phi\_1, \Phi\_2$由下式计算：$$\begin{align\*} & w\_{id}  = \Phi\_1 = \frac1{1+exp({-\frac{f\_i}{ap}})} \\\\ & \Phi\_2 = \begin{cases} 1, & 雇佣蜂 \\\\ \frac1{1+exp({-{f\_i}/{ap}})}, & 观察蜂 \end{cases} \end{align\*} $$其中，$ap$是第一次迭代中的适应度。通过加速因子$\Phi\_2$实现了区分雇佣蜂和观察蜂寻找邻域食物源的过程，使得算法能够有更快的收敛速度。

&emsp;&emsp;总的来说，人工蜂群优化算法也是一种局部随机搜索算法；适用于求解函数优化问题。

## 小结
&emsp;&emsp;本文主要介绍了集群智能的三个代表性算法及其改进：蚁群优化算法、粒子群优化算法和人工蜂群优化算法。蚁群算法基于蚁群寻食的过程，主要解决图的最优路径搜索问题；粒子群优化算法启发于鸟群的群体运动行为，主要解决连续解空间的优化问题；人工蜂群优化算法基于蜂群寻食交流过程，求解函数优化问题很有效。

[TOC]

